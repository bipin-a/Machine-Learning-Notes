{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Window Creation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPht3Xd0ARQDfZDnheG3yeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bipin-a/Machine-Learning-Notes/blob/main/Window_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "from scipy.signal import find_peaks\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from datetime import timedelta\n",
        "from math import log2\n",
        "from scipy.signal import peak_prominences\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import random\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Union\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy.typing as npt"
      ],
      "metadata": {
        "id": "wXPhmVGOsq8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsv5BHFNWUpC",
        "outputId": "6fc1f383-6f32-4f83-8463-3d813cc49828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2ycHDQ75b5A",
        "outputId": "660a0601-167c-4f73-a71c-7311248ab0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/Shareddrives/BipinA/Neural_Networks_Data/\""
      ],
      "metadata": {
        "id": "yAnIEMY85TOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_features = pd.concat([pd.read_csv(f\"{data_dir}daily_features.csv\"),pd.read_csv(f\"{data_dir}daily_features_pt2.csv\")])\n",
        "weekly_features = pd.read_csv(f\"{data_dir}weekly_features.csv\")\n",
        "monthly_features = pd.concat([pd.read_csv(f\"{data_dir}monthly_features_1.csv\"),\n",
        "                              pd.read_csv(f\"{data_dir}monthly_features_2.csv\"),\n",
        "                              pd.read_csv(f\"{data_dir}monthly_features_3.csv\"),\n",
        "                              pd.read_csv(f\"{data_dir}monthly_features_4.csv\"),\n",
        "                              pd.read_csv(f\"{data_dir}monthly_features_5.csv\"),\n",
        "                              ])\n",
        "\n",
        "all_features = pd.concat([daily_features,weekly_features,monthly_features])\n",
        "del daily_features, weekly_features, monthly_features"
      ],
      "metadata": {
        "id": "edZp0-Rkyo0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series = all_features.fit_forecast.map(lambda x : json.loads(x).get(\"raw\") )\n",
        "time_series = pd.concat([time_series, all_features.V1, all_features.forecast_error], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "5bXmRbgJewzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series['FREQ'] = time_series['V1'].apply(lambda x :x[0])"
      ],
      "metadata": {
        "id": "ok0qAH7im00Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series[time_series.fit_forecast.apply(len) > time_series.fit_forecast.apply(len).quantile(0.45)].groupby(\"FREQ\").count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "tgjTc1uymqE6",
        "outputId": "fcd3cda3-fcc3-4a0a-d33d-db5a9a5f452a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fit_forecast    V1  forecast_error\n",
              "FREQ                                    \n",
              "D             3352  3352            3352\n",
              "M             4004  4004            4004\n",
              "W              286   286             286"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f0c9970-b277-4c38-a2cf-276fa3e70a5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_forecast</th>\n",
              "      <th>V1</th>\n",
              "      <th>forecast_error</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FREQ</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <td>3352</td>\n",
              "      <td>3352</td>\n",
              "      <td>3352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>4004</td>\n",
              "      <td>4004</td>\n",
              "      <td>4004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W</th>\n",
              "      <td>286</td>\n",
              "      <td>286</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f0c9970-b277-4c38-a2cf-276fa3e70a5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f0c9970-b277-4c38-a2cf-276fa3e70a5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f0c9970-b277-4c38-a2cf-276fa3e70a5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "large_time_series = time_series[time_series.fit_forecast.apply(len) > time_series.fit_forecast.apply(len).quantile(0.45)]\n"
      ],
      "metadata": {
        "id": "H7neLkHhm6tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_time_series = pd.concat( [\n",
        "                    large_time_series[(large_time_series.FREQ==\"D\") & (large_time_series.forecast_error < 0.1)].sample(1100),\n",
        "                    large_time_series[(large_time_series.FREQ==\"M\") & (large_time_series.forecast_error < 0.1)].sample(1100),\n",
        "                    large_time_series[(large_time_series.FREQ==\"W\") & (large_time_series.forecast_error < 0.1)] \n",
        "                    ] )\n",
        "                                \n"
      ],
      "metadata": {
        "id": "L8EageermXUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(sample_time_series.FREQ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "KN1bAMy1nWCZ",
        "outputId": "e10792cb-7d17-4da7-bac1-08dd2f134327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1100.,    0.,    0.,    0.,    0., 1100.,    0.,    0.,    0.,\n",
              "         217.]),\n",
              " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Train it on all data \n",
        "\n",
        "2. Train each model on one feature of data (i.e highly periodic) \n",
        "\n",
        "\n",
        "In scope:\n",
        "Find which model does the best on what features.\n",
        "\n",
        "Out of scope:\n",
        "Train that model on those time series specifically --> "
      ],
      "metadata": {
        "id": "y5IzdPgHUKJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN is better for series with low trend and high periodicity "
      ],
      "metadata": {
        "id": "cgaOUdgcT6dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment A: \n",
        "\n",
        "Preprocessing: \n",
        "- Normalize: Standardize  \n",
        "\n",
        "Training \n",
        "1. MAE error function\n",
        "2. cumlative error function \n",
        "\n",
        "Testing \n",
        "1. 30 Days\n",
        "2. 90 Days\n",
        "3. 180 Days\n",
        "\n",
        "Models:\n",
        "- ANN\n",
        "- LSTM\n",
        "- CNN\n",
        "- RNN\n",
        "\n",
        "# Experiment B: \n",
        "Preprocessing:\n",
        "- Normalize: Z score\n",
        "\n",
        "Training \n",
        "1. MAE error function\n",
        "2. cumlative error function \n",
        "\n",
        "Testing \n",
        "1. 30 Days\n",
        "2. 90 Days\n",
        "3. 180 Days\n",
        "\n",
        "Models:\n",
        "- ANN\n",
        "- LSTM\n",
        "- CNN\n",
        "- RNN\n",
        "\n",
        "\n",
        "# Experiment C: \n",
        "Preprocessing:\n",
        "None\n",
        "\n",
        "Training \n",
        "1. MAE error function\n",
        "2. cumlative error function\n",
        "\n",
        "Testing \n",
        "1. 30 Days\n",
        "2. 90 Days\n",
        "3. 180 Days\n",
        "\n",
        "Models:\n",
        "- ANN\n",
        "- LSTM\n",
        "- CNN\n",
        "- RNN\n",
        "\n",
        "Losses\n",
        "\n",
        "The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n",
        "\n",
        "Metrics\n",
        "\n",
        "A metric is a function that is used to judge the performance of your model.\n",
        "Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.\n",
        "\n"
      ],
      "metadata": {
        "id": "SQiFQ9Ry-9ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1"
      ],
      "metadata": {
        "id": "nvQg5KkGDCy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_X_Y_windows(series:pd.Series,\n",
        "                    INPUT_SIZE:int,\n",
        "                    OUTPUT_SIZE:int, \n",
        "                    STEP_SIZE:int,\n",
        "                    _scaler) -> Union[npt.NDArray,npt.NDArray]:\n",
        "  \n",
        "  test_end = series.shape[0] \n",
        "  test_start = test_end - OUTPUT_SIZE\n",
        "  train_end = test_start - 1\n",
        "  train_start =  train_end - INPUT_SIZE\n",
        "\n",
        "  all_features = []\n",
        "  all_labels = []\n",
        "\n",
        "  while train_start > 0:\n",
        "    features = np.array(series.iloc[train_start:train_end].values)\n",
        "    label = np.array(series.iloc[test_start:test_end].values)\n",
        "\n",
        "    min,max, mean, std = get_stats(features)\n",
        "    features = custom_scaler(scaler=_scaler, X=features,\n",
        "                                min=min, max=max,\n",
        "                                mean=mean, std=std)\n",
        "    label = custom_scaler(scaler=_scaler, X=label,\n",
        "                                min=min, max=max,\n",
        "                                mean=mean, std=std)\n",
        "\n",
        "    all_features.append(features)\n",
        "    all_labels.append(label)\n",
        "    test_end -= STEP_SIZE\n",
        "    test_start = test_end - OUTPUT_SIZE\n",
        "    train_end = test_start - 1\n",
        "    train_start =  train_end - INPUT_SIZE\n",
        "  \n",
        "  return np.array(all_features), np.array(all_labels)"
      ],
      "metadata": {
        "id": "ZddwLLwWuYvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Experiment = namedtuple(\"Experiment\", \"X_train Y_train X_test Y_test X_val Y_val OUTPUT_SIZE scaler_name TS_Train TS_Test TS_Val\")"
      ],
      "metadata": {
        "id": "DZxXU6AWp2jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MinMax:\n",
        "  def scale(self,X:pd.Series, min:int, max: int):\n",
        "    return  (X - min) / (max - min) \n",
        "\n",
        "class Standardize:\n",
        "  def scale(self, X:pd.Series, mean:int, std: int) -> pd.Series:\n",
        "    return (X-mean) / std\n",
        "\n",
        "class Nada:\n",
        "  def scale(self, X:pd.Series, mean:int, std: int) -> pd.Series:\n",
        "    return None\n",
        "\n",
        "def custom_scaler(scaler, X:pd.Series, min:int, max:int,mean:int, std: int) -> pd.Series:\n",
        "  if type(scaler).__name__ == \"MinMax\": \n",
        "    return scaler.scale(X, min, max)\n",
        "  elif type(scaler).__name__ == \"Standardize\":\n",
        "    return scaler.scale(X, mean, std)\n",
        "  elif type(scaler).__name__ == \"Nada\":\n",
        "    return X\n",
        "\n",
        "def get_stats(X:npt.NDArray)-> list:\n",
        "  min = np.min(X)\n",
        "  max = np.max(X)\n",
        "  mean = np.mean(X)\n",
        "  std = np.std(X)\n",
        "  return [min, max, mean, std]"
      ],
      "metadata": {
        "id": "t0kzs6c4iAhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.enable()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wQUGw4WfTXi",
        "outputId": "6b4c5b7b-d079-4bfb-dd27-490f8e156989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "322"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.enable()\n",
        "gc.collect()\n",
        "INPUT_SIZE = 300\n",
        "output_sizes = [30,120,270]\n",
        "STEP_SIZE = 3\n",
        "minmaxscaler = MinMax()\n",
        "standardizescaler = Standardize()\n",
        "nada = Nada()\n",
        "n_features = 1\n",
        "\n",
        "for OUTPUT_SIZE in output_sizes:\n",
        "    for scaler in [minmaxscaler, standardizescaler, nada]:\n",
        "        # Experiment begins\n",
        "        X_val = np.empty((INPUT_SIZE), int)\n",
        "        Y_val = np.empty((OUTPUT_SIZE), int)\n",
        "        X_train = np.empty((INPUT_SIZE), int)\n",
        "        Y_train = np.empty((OUTPUT_SIZE), int)\n",
        "        X_test = np.empty((INPUT_SIZE), int)\n",
        "        Y_test = np.empty((OUTPUT_SIZE), int)\n",
        "        TS_Train = []\n",
        "        TS_Test = []\n",
        "        TS_Val = []\n",
        "        scaler_name = type(scaler).__name__\n",
        "        EXP_NAME = str(OUTPUT_SIZE) + str(scaler_name)\n",
        "        print(EXP_NAME)\n",
        "        # TODO: Shuffle the time seriesdf\n",
        "        c=0\n",
        "        for row in sample_time_series.itertuples():\n",
        "            ts_id = row.V1\n",
        "            sample = pd.Series(row.fit_forecast)\n",
        "            TOT = OUTPUT_SIZE + INPUT_SIZE + 100\n",
        "            if (len(sample)>(TOT*2)):\n",
        "                c += 1\n",
        "                TEST_raw = sample.iloc[-TOT:]\n",
        "                TRAIN_raw = sample.iloc[:-TOT]\n",
        "                \n",
        "                \n",
        "                features_insample, labels_insample = get_X_Y_windows(TRAIN_raw,INPUT_SIZE,\n",
        "                                                                        OUTPUT_SIZE, STEP_SIZE, scaler)\n",
        "                _x_train,_x_val,_y_train,_y_val = train_test_split(features_insample, \n",
        "                                                                    labels_insample,\n",
        "                                                                    shuffle=True,\n",
        "                                                                    random_state=1)\n",
        "                    \n",
        "                features_test, labels_test = get_X_Y_windows(TEST_raw,INPUT_SIZE,OUTPUT_SIZE, STEP_SIZE, scaler)\n",
        "\n",
        "                ts_id_test = [ts_id for i in range(features_test.shape[0])]\n",
        "                ts_id_train = [ts_id for i in range(_x_train.shape[0])]\n",
        "                ts_id_val = [ts_id for i in range(_x_val.shape[0])]\n",
        "                # print(\"len id: \", len(ts_id_test))\n",
        "                # print(\"features_test shape: \", features_test.shape)\n",
        "\n",
        "                X_test = np.vstack((X_test,features_test))\n",
        "                Y_test = np.vstack((Y_test,labels_test))\n",
        "                X_train = np.vstack((X_train,_x_train))\n",
        "                Y_train = np.vstack((Y_train, _y_train))\n",
        "                X_val = np.vstack((X_val,_x_val))\n",
        "                Y_val = np.vstack((Y_val,_y_val))\n",
        "                TS_Train.extend(ts_id_train)\n",
        "                TS_Test.extend(ts_id_test)\n",
        "                TS_Val.extend(ts_id_val)\n",
        "            else:\n",
        "                continue\n",
        "        print(\"Number of time series samples: \", c)\n",
        "        X_test = X_test[1:]\n",
        "        Y_test = Y_test[1:]\n",
        "        X_train = X_train[1:]\n",
        "        Y_train = Y_train[1:]\n",
        "        X_val = X_val[1:]\n",
        "        Y_val = Y_val[1:]\n",
        "\n",
        "        # Samples for X and Y should be same within the split\n",
        "        num_samples = X_train.shape[0]\n",
        "        X_train = X_train.reshape((num_samples, INPUT_SIZE, n_features))\n",
        "        Y_train = Y_train.reshape((num_samples, OUTPUT_SIZE, n_features))\n",
        "        \n",
        "        num_samples = X_test.shape[0]\n",
        "        X_test = X_test.reshape((num_samples, INPUT_SIZE, n_features))\n",
        "        # Y_test = Y_test.reshape((num_samples, E.OUTPUT_SIZE, n_features))  Not reshaping y_test, in order to plot easier later on\n",
        "\n",
        "        num_samples = X_val.shape[0]\n",
        "        X_val = X_val.reshape((num_samples, INPUT_SIZE, n_features))\n",
        "        Y_val = Y_val.reshape((num_samples, OUTPUT_SIZE, n_features))\n",
        "              \n",
        "        # At the end of one experiment, add list of all data\n",
        "        E = Experiment(X_train, Y_train, X_test, Y_test,\n",
        "                                          X_val, Y_val, OUTPUT_SIZE, scaler_name, \n",
        "                                          TS_Train, TS_Test, TS_Val)\n",
        "        import pickle\n",
        "        with open(f\"{data_dir}_ExperimentDictionary_{EXP_NAME}.pickle\", 'wb') as f:\n",
        "            pickle.dump(E, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "JEomqjbS1BE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7b0a0d-59dc-48db-f6ca-3c9b6af84b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30MinMax\n",
            "Number of time series samples:  1050\n",
            "30Standardize\n",
            "Number of time series samples:  1050\n",
            "30Nada\n",
            "Number of time series samples:  1050\n",
            "120MinMax\n",
            "Number of time series samples:  986\n",
            "120Standardize\n",
            "Number of time series samples:  986\n",
            "120Nada\n",
            "Number of time series samples:  986\n",
            "270MinMax\n",
            "Number of time series samples:  889\n",
            "270Standardize\n",
            "Number of time series samples:  889\n",
            "270Nada\n",
            "Number of time series samples:  889\n"
          ]
        }
      ]
    }
  ]
}